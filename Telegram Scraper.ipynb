{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting & Analyzing Telegram Public Channel Data\n",
    "Eli Lewien & Michael Baldassaro\n",
    "\n",
    "This Jupyter Notebook contains code to enable you to: \n",
    "\n",
    "1. Collect messages, images, video, and audio files from public channels on the Telegram messaging app\n",
    "2. Perform basic keyword searches to filter content for further manual review and analysis  \n",
    "\n",
    "Before using this script, you will need to: \n",
    "\n",
    "* Create a Telegram account (if you don't have one already)\n",
    "* Create an app to obtain API credentials:\n",
    "    * Log in to https://my.telegram.org/\n",
    "    * Click on 'API development tools'\n",
    "    * Create an app to generate an api_id and api_hash "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will import the packages needed to execute your script and enter the API credentials you obtained when you created your app. \n",
    "\n",
    "Replace the values for the name, api_id, and api_hash below with your name and credentials then click execute.\n",
    "\n",
    "This script also creates three empty folders - video, img and audio - where audio visual content contained in messages will be downloaded and stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "from telethon import functions, types\n",
    "from telethon.sync import TelegramClient\n",
    "import numpy as np\n",
    "\n",
    "path_vid = 'video'; os.mkdir(path_vid) #creates empty video folder to hold videos\n",
    "path_img = 'img'; os.mkdir(path_img) #image folder\n",
    "path_aud = 'audio'; os.mkdir(path_aud) #audio folder\n",
    "\n",
    "name = 'your username' #if no user name, enter 'anon' - it should work just fine!\n",
    "api_id = 'your id' #the 'App api_id' from the app you created in https://my.telegram.org/apps\n",
    "api_hash = 'your hash' #the 'App api_hash' from the app you created in https://my.telegram.org/apps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you list the Telegram handles (@userhandle) for the public channel(s) from which you want to collect messages. \n",
    "\n",
    "For the purposes of this example, we're using the handles of the New York Times (@nytimes) & Fox News (@FoxNewsTG)\n",
    "\n",
    "If you wanted to collect messages from channels of US-based extremist groups, e.g., The Proud Boys (@proudboysusa), Texas Three Percenters (@TexasThreePercent], etc. or conspiracy groups, e.g., QAnon Warriors (@QAnon Warriors), American Patriot Movement (@AmericanPatriotsMovement), etc. just replace the values for channels in the code block below with the handles of channels for which you would like to collect messages then execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = ['nytimes', 'FoxNewsTG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the time period for which you would like to collect messages. \n",
    "\n",
    "For this example, we set a start time of June 25, 2022 at 00:00:00 UTC and an end time of June 25, 2022 at 23:59:59 UTC to collect one full day of messages. \n",
    "\n",
    "Replace the parameter values for start_time and end_time with the dates and times for which you would like to collect messages then execute.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime(2022, 6, 25, 0, 0, 0) #params: year, month, day, hour, minute, second\n",
    "start_time = start_time.replace(tzinfo=timezone.utc) #sets the timezone to UTC\n",
    "end_time = datetime(2022, 6, 25, 23, 59, 59)\n",
    "end_time = end_time.replace(tzinfo=timezone.utc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now execute the following script to iterate through the channels to: \n",
    "\n",
    "* Collect data on the senders, messages, links, number of message views, and number of message forwards. \n",
    "* Generate a csv file of the data and store it the main folder with the date the data was collected \n",
    "* Download video, images, or audio files associated with messages and store them in folders\n",
    "\n",
    "When you execute this script, you may be prompted to enter the phone number associated with your account and then a verification code you receive via Telegram to confirm your identity. If you do not enter your phone number and verification code, the script will run in an endless loop and no data will be collected!\n",
    "\n",
    "Once the script has finished executing, you should see an output dataframe of the all data that was collected and stored in an object called 'df' (note: this is also what is contained in the csv file that is generated) \n",
    "\n",
    "Note: Depending on the volume of posts, this script may take anywhere from a few seconds to several minutes (or more) to execute. When done, the  This pulls multiple of the same post at the same timestamp but each with different view counts. Monitors have sorted posts in CSV to remove extra posts, but could clean up with script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] \n",
    "now = str(datetime.now().date())\n",
    "\n",
    "for channel in channels:   \n",
    "    async with TelegramClient(name, api_id, api_hash) as client:\n",
    "        async for message in client.iter_messages('t.me/'+ str(channel)):\n",
    "            if end_time > message.date and message.date > start_time:\n",
    "                if message.photo: \n",
    "                    await message.download_media(file=path_img)\n",
    "                elif message.video:\n",
    "                    await message.download_media(file=path_vid)\n",
    "                elif message.audio:\n",
    "                    await message.download_media(file=path_aud)\n",
    "                data.append([channel, 't.me/'+ str(channel)+ '/' + str(message.id), message.sender_id, message.date, message.forwards, message.views, message.text])\n",
    "      \n",
    "df = pd.DataFrame(data, columns=['channel','link', 'sender', 'date', 'forwards', 'views', 'message'])\n",
    "df.to_csv('telegram' + now + '.csv', encoding='utf-8') \n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! In just a few lines of code, you've successfully collected message data and audio visual files from public channels of interest on Telegram.\n",
    "\n",
    "You can now mine and analyze this data to see what content is getting the most views, generating the most forwards, and / or may be harmful in some way. \n",
    "\n",
    "In Myanmar, the team used a two-step approach to identify content that was harmful: \n",
    "1. Check to see if messages contained one or more keywords commonly associated with possible disinformation and hate speech in the Burmese context\n",
    "2. Task staff with reviewing messages that contained such keywords to evaluate whether individual pieces of content were actually harmful. \n",
    "\n",
    "This approach effectively enabled the team to sift through a large volume of data and isolate potentially harmful content for manual review and analysis. \n",
    "\n",
    "For the purposes of this illustrative example, we're going to use an oversimplified approach to identify what proportion of messages in the New York Times and Fox News Telegram channels was related to the US Supreme Court decision to overturn Roe v. Wade, which was issued the day before the data was collected. We use a very short (and certainly non-extensive) list of keywords: 'roe' 'wade' 'supreme court', 'abortion', 'pro-choice', 'pro-life'.\n",
    "\n",
    "To make our keyword search work:\n",
    "\n",
    "* We create a new column in our dataframe ('text') that contains the message in all lowercase letters \n",
    "* We search for keywords found in the text and, for all that appear, add those keywords in a new column called 'keyword' \n",
    "* We assign a value of 1 if any of the keywords are found in the text - or a value of 0 where they don't - in a new column called 'mention'\n",
    "\n",
    "Once the script has finished executing, you should see an output dataframe with additional columns \n",
    "\n",
    "Replace any of the values in keywords with keywords of your choice and execute the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['roe', 'wade', 'supreme court', 'abortion', 'pro-choice', 'pro-life']\n",
    "df['text'] = pd.Series(df['message']).str.lower()\n",
    "\n",
    "df['keyword'] = df['text'].str.findall('|'.join(keywords)).apply(set).str.join(', ')\n",
    "df['mention'] = np.where(df['keyword'] == \"\", 0, 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(NB: alternatively, if we wanted to see which specific keywords were mentioned in a given message and assign a 1 or a 0 to signify whether that keyword appeared in the message, we could use the following script to do that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search(message, keywords):\n",
    "    if keywords in message:\n",
    "        return int(1)\n",
    "    else:\n",
    "        return int(0)\n",
    "\n",
    "for keyword in keywords:\n",
    "    df[keyword] = df['text'].apply(lambda t: keyword_search(t, keyword))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this code is pretty basic, it is a good starting point to enable you to collect data from Telegram and perform some analysis of content. There is much more that can be done using Natural Language Processing (NLP) and Social Network Analysis (SNA) methods to extract prominent keywords, evaluate sentiment, and perform topical analysis. Those approaches will be explored and documented in future notebooks.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d4d2efe85d8abd466944938bdbd52f9f98e985ee79419b7758ec601485c4831"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
